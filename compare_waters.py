import sys
import math
import argparse
import os

# --- GLOBAL CONFIGURATION ---
# Set your desired output folder here. 
# Examples: "results", "/home/user/output", "comparison_output"
OUTPUT_DIR = "comparison"
# ----------------------------

def parse_pdb_points(filename):
    """
    Parses a PDB file and extracts specific atoms based on name.
    Now supports:
      - Water Oxygens (O, OW)
      - Cavity Dummy Atoms (XP)
    
    Returns a list of dictionaries containing coordinates and the raw line.
    """
    points = []
    # Define which atom names we want to capture
    target_atoms = {'O', 'OW', 'XP'}
    
    try:
        with open(filename, 'r') as f:
            for line in f:
                if line.startswith(('ATOM', 'HETATM')):
                    # PDB Column standards (0-indexed):
                    # Atom Name: 12-16
                    # Coordinates: 30-54
                    atom_name = line[12:16].strip()
                    
                    if atom_name in target_atoms:
                        try:
                            # Standard PDB fixed-width parsing
                            x = float(line[30:38])
                            y = float(line[38:46])
                            z = float(line[46:54])
                            
                            points.append({
                                'line': line,
                                'coords': (x, y, z),
                                'matched': False,
                                'id': len(points) 
                            })
                        except ValueError:
                            # Handle cases where columns might be malformed
                            continue
    except FileNotFoundError:
        print(f"Error: File {filename} not found.")
        sys.exit(1)
        
    return points

def get_grid_key(coords, cell_size=1.0):
    """Generates a spatial hash key for 3D coordinates."""
    return (
        int(math.floor(coords[0] / cell_size)),
        int(math.floor(coords[1] / cell_size)),
        int(math.floor(coords[2] / cell_size))
    )

def build_spatial_grid(points, cell_size=1.0):
    """
    Organizes points into a dictionary grid based on location 
    for O(1) average lookup time.
    """
    grid = {}
    for p in points:
        key = get_grid_key(p['coords'], cell_size)
        if key not in grid:
            grid[key] = []
        grid[key].append(p)
    return grid

def get_neighbor_keys(center_key):
    """Returns the keys for the center cell and its 26 neighbors."""
    cx, cy, cz = center_key
    neighbors = []
    for dx in [-1, 0, 1]:
        for dy in [-1, 0, 1]:
            for dz in [-1, 0, 1]:
                neighbors.append((cx + dx, cy + dy, cz + dz))
    return neighbors

def distance_sq(c1, c2):
    """Calculates squared Euclidean distance (faster than sqrt)."""
    return (c1[0]-c2[0])**2 + (c1[1]-c2[1])**2 + (c1[2]-c2[2])**2

def write_pdb(filename, points):
    """Writes a list of point dictionaries to a PDB file."""
    try:
        with open(filename, 'w') as f:
            f.write("REMARK Generated by Point Comparison Script\n")
            for p in points:
                f.write(p['line'])
            f.write("END\n")
        print(f"-> Wrote {len(points)} atoms to {filename}")
    except IOError as e:
        print(f"Error writing to {filename}: {e}")

def generate_output_name(input_path, output_dir, prefix="unique_to_"):
    """
    Creates an output filename using the global OUTPUT_DIR and the original filename.
    Ex: input='folder/data.pdb', output_dir='results' -> output='results/unique_to_data.pdb'
    """
    filename = os.path.basename(input_path)
    name, ext = os.path.splitext(filename)
    new_filename = f"{prefix}{name}{ext}"
    return os.path.join(output_dir, new_filename)

def main():
    parser = argparse.ArgumentParser(description="Compare coordinates (Waters/XP) in two PDB files.")
    parser.add_argument("file1", help="Input PDB File 1")
    parser.add_argument("file2", help="Input PDB File 2")
    parser.add_argument("--tolerance", type=float, default=0.01, help="Distance tolerance in Angstroms (default: 0.01)")
    
    args = parser.parse_args()

    # Ensure output directory exists
    if not os.path.exists(OUTPUT_DIR):
        try:
            os.makedirs(OUTPUT_DIR)
            print(f"Created output directory: {OUTPUT_DIR}")
        except OSError as e:
            print(f"Error creating directory {OUTPUT_DIR}: {e}")
            sys.exit(1)
    
    print(f"Reading {args.file1}...")
    points1 = parse_pdb_points(args.file1)
    
    print(f"Reading {args.file2}...")
    points2 = parse_pdb_points(args.file2)

    print(f"Comparing {len(points1)} points from File 1 against {len(points2)} points from File 2...")
    print(f"Tolerance: {args.tolerance} A")

    # Optimization: Build a spatial grid for File 2
    grid_size = 1.0 # Angstrom bucket size
    grid2 = build_spatial_grid(points2, grid_size)
    
    common_points = []
    unique_file1 = []
    
    tol_sq = args.tolerance ** 2
    
    # Iterate through File 1 and look for matches in File 2's grid
    for p1 in points1:
        key = get_grid_key(p1['coords'], grid_size)
        possible_keys = get_neighbor_keys(key)
        
        match_found = False
        
        for n_key in possible_keys:
            if n_key in grid2:
                for p2 in grid2[n_key]:
                    # Check distance
                    if distance_sq(p1['coords'], p2['coords']) <= tol_sq:
                        # Match found!
                        p2['matched'] = True
                        match_found = True
                        
                        # Add the line from File 1 to the common list
                        common_points.append(p1)
                        break 
            if match_found:
                break
        
        if not match_found:
            unique_file1.append(p1)

    # Collect points in File 2 that were never matched
    unique_file2 = [p for p in points2 if not p['matched']]

    # --- Generate Output Filenames ---
    # Files will be saved to the global OUTPUT_DIR
    out_name_1 = generate_output_name(args.file1, OUTPUT_DIR, prefix="unique_to_")
    out_name_2 = generate_output_name(args.file2, OUTPUT_DIR, prefix="unique_to_")
    out_name_common = os.path.join(OUTPUT_DIR, "common_points.pdb")

    # Output
    print("\n--- Results ---")
    write_pdb(out_name_1, unique_file1)
    write_pdb(out_name_2, unique_file2)
    write_pdb(out_name_common, common_points)

if __name__ == "__main__":
    main()